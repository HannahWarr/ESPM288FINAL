# Unit I: Climate Change Module

## Opening Tutorial: Examining CO2 trends in python

-   Example from <http://climate.nasa.gov/vital-signs/carbon-dioxide/>
-   Raw data from <https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt>

```{r}
library(ggplot2)
library(dplyr)
library(lubridate)
library(tidyverse)

```

```{r}
#read in data
columns = c('year', 'month', 'decimal_date', 'average', 'smooth', 'std_days', 'uncertainty', 'empty')
df = read.table("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt", col.names =  columns)
df
```

```{r}
#plot the data
ggplot(df, aes(decimal_date, average)) +
  geom_line(color = "blue") +
  xlab("Year") +
  ylab("Average CO2")
  

```

```{r}
#averaging all the months

co2_tidy <- df %>%
  group_by(month) %>%
  summarize(average = mean(average, na.rm = TRUE)) 
co2_tidy

```

```{r}
# plot the averages on an average year

ggplot(co2_tidy, aes(month, average)) +
  geom_line(color = "steelblue") +
  labs(title = "Annual Average CO2",
       x = "Months",
       y = "CO2 (ppm)") +
  theme_minimal()
```

Which months are the CO2 values at the maximum? Minimum? Why is this?

-   Max is at April (early spring) and Min is near September (Fall) Maybe this is due to the fact that most vegetation is more active during summer, taking away lots of CO2 from atmosphere.

------------------------------------------------------------------------

# Exercise I: Temperature Data

Each of the last years has consecutively set new records on global climate. In this section we will analyze global mean temperature data.

Data from: <http://climate.nasa.gov/vital-signs/global-temperature>

## Question 1:

Describe the data set to the best of your ability given the documentation provided. Describe what kind of column each data contains and what units it is measured in. Then address our three key questions in understanding this data:

-   How are the measurements made? What is the associated measurement uncertainty?

-   What is the resolution of the data?

-   Are their missing values? How should they be handled?

```{r}
#The data is collected is global surface temperature compared to a long term average from 1951-1980

#Columns are 'Year' data was collected (discrete data), temp in C with 'No_smoothing', and a temp in C that is smoothed using 'Lowess' method

    # Measurements made a from GISS which seems to be using satellites and space probes
    # Data is collected to the hundredth of a C degree
    # to find missing values we need to ask with the code "sum(is.na(ice))", which we should then throw out any missing values
```

## Question 2:

Construct the necessary r code to import and prepare for manipulation the following data set: <http://climate.nasa.gov/system/internal_resources/details/original/647_Global_Temperature_Data_File.txt>

```{r}
#read in data
columns = c('Year', 'No_smoothing', 'Lowess')
df = read.table("https://data.giss.nasa.gov/gistemp/graphs/graph_data/Global_Mean_Estimates_based_on_Land_and_Ocean_Data/graph.txt", skip=5, col.names = columns)
df
```

```{r}
#checking for missing values
sum(is.na(df))
#and there is none so we don't need to worry about not including them in the data
```

## Question 3:

Plot the trend in global mean temperatures over time. Describe what you see in the plot and how you interpret the patterns you observe.

```{r}
#plotting the data

ggplot(df, aes(x = Year)) +
  geom_line(aes(y = No_smoothing, color = "No smoothing", linetype = "No smoothing")) +
  geom_line(aes(y = Lowess, color = "Lowess", linetype = "Lowess")) +
  labs(title = "Global Mean Temperature Anomaly",
       x = "Year",
       y = "Temperature Anomaly (Â°C)",
       color = "Line Type",
       linetype = "Line Type") +
  scale_color_manual(values = c("No smoothing" = "steelblue", "Lowess" = "darkred")) +
  scale_linetype_manual(values = c("No smoothing" = "dashed", "Lowess" = "solid")) +
  theme_minimal()
```

# Exercise II: Melting Ice Sheets?

-   Data description: <http://climate.nasa.gov/vital-signs/land-ice/>
-   Raw data file: <http://climate.nasa.gov/system/internal_resources/details/original/499_GRN_ANT_mass_changes.csv>

## Question 1:

-   Describe the data set: what are the columns and units? Where do the numbers come from?
-   What is the uncertainty in measurement? Resolution of the data? Interpretation of missing values?

```{r}

#    - There are three columns. First is year in decimal notation, second is the mass of ice in Greenland, and third is the mass of ice in Antarctica. Data is collected from NASA's GRACE satellites
#    - The units are gigatonnes. The data is from the GRACE satellite mission. The uncertainty is 10 gigatonnes (this information was filled in by AI and I cannot find the verification of it). 
#    - The resolution is two decimal places. No missing values, but I can find them using is.na()

```

## Question 2:

Construct the necessary code to import this data set.

```{r}
columns = c('decimal_date', 'greenland_mass', 'antarctica_mass')
ice = read.csv("http://climate.nasa.gov/system/internal_resources/details/original/499_GRN_ANT_mass_changes.csv", col.names= columns, skip=9)
ice

```

```{r}
#checking for missing values in file
sum(is.na(ice))

```

## Question 3:

Plot the data and describe the trends you observe.

```{r}
#plotting data
ggplot(ice, aes(x = decimal_date)) +
  geom_line(aes(y = greenland_mass, color = "Greenland", linetype = "Greenland")) +
  geom_line(aes(y = antarctica_mass, color = "Antarctica", linetype = "Antarctica")) +
  labs(title = "Ice masses over time",
       x = "Year",
       y = "Mass of Ice (Gt)",
       color = "Location",
       linetype = "Location") +
  scale_color_manual(values = c("Greenland" = "darkgreen", "Antarctica" = "darkblue")) +
  scale_linetype_manual(values = c("Greenland" = "solid", "Antarctica" = "solid")) +
  theme_minimal()
```

```{r}
#if i wanted to split graph into two panels

#mutate data 

ice_long <- ice %>%
  pivot_longer(cols = c(greenland_mass, antarctica_mass),
               names_to = "location",
               values_to = "mass") %>%
  mutate(location = recode(location,
                           greenland_mass = "Greenland",
                           antarctica_mass = "Antarctica"))

ggplot(ice_long, aes(x = decimal_date, y = mass, color = location)) +
  geom_line() +
  facet_wrap(~ location, nrow = 1) +  # Side-by-side panels
  scale_color_manual(values = c("Greenland" = "darkgreen", "Antarctica" = "darkblue")) +
  labs(title = "Ice Masses Over Time",
       x = "Year",
       y = "Mass of Ice (Gt)",
       color = "Location") +
  theme_minimal()

#this honestly feels like too much work, but valuable to have this plotting method in my repertoire
```

```{r}
#NOW I WANT TO MAKE A MAP OF ICE CAPS
```

# Exercise III: Rising Sea Levels?

-   Data description: <http://climate.nasa.gov/vital-signs/sea-level/>
-   Raw data file: <http://climate.nasa.gov/system/internal_resources/details/original/121_Global_Sea_Level_Data_File.txt>

## Question 1:

-   Describe the data set: what are the columns and units?
-   Where do these data come from?
-   What is the uncertainty in measurment? Resolution of the data? Interpretation of missing values?

```{r}
# Data is quantifying global sea level rise. There are twelve columns. The column names are listed in the headers. Of all the columns, the ones we will likely focus on are Year (given in continuous decimal date), and the last column which is smoothed GMSL GIA applied variation in mm with annual and semi-annual signal removed

#data comes from Global Mean sea level which is computed at NASa Goddard Space Flight Center which combines Sea Surface Heights from TOPEX/Poseidon, Jason-1 and OSTM/Jason-2

#data is collected in mm, with very little uncertainty. Missing values are listed by 99900.00
```

## Question 2:

Construct the necessary R code to import this data set as a tidy `Table` object.

```{r}
#read in data
columns = c('type', 'file', 'decimal_date', 'observations', 'weighted_observations', 'GMSL_TOPEX', 'std_GMSL_TOPEX', 'unknown', 'GMSL_TOPEX_GIA' , 'std_GMSL_TOPEX_GIA' ,'smoothed_GMSL', 'smoothed_GMSL_nosignal')
df = read.table("http://climate.nasa.gov/system/internal_resources/details/original/121_Global_Sea_Level_Data_File.txt", col.names = columns, skip = 47)
df <- df[df$type != 999, ]
df

```

## Question 3:

Plot the data and describe the trends you observe.

```{r}
ggplot(df, aes(x = decimal_date)) +
  geom_ribbon(aes(ymin= smoothed_GMSL_nosignal - 4 + 14.09, ymax = smoothed_GMSL_nosignal +4 + 14.09), fill ="lightblue")  + #website says 4.0 mm is uncertainty level
  geom_line(aes(y = smoothed_GMSL_nosignal + 14.09)) + #because this is since 1993 I need to subtract the original sea level (also done above)
  labs(title = "Sea Level Rise",
       x = "Year",
       y = "Sea Height Variation (mm)") +
  theme_minimal()

```

# Exercise IV: Arctic Sea Ice?

-   <http://nsidc.org/data/G02135>
-   <https://noaadata.apps.nsidc.org/NOAA/G02135/north/monthly/data/>

## Question 1:

-   Describe the data set: what are the columns and units?
-   Where do these data come from?
-   What is the uncertainty in measurement? Resolution of the data? Interpretation of missing values?

```{r}
 # -data is in several csv file with a column for: year, month, data type, region (all N), extent, and area. From what I have seen they are in km
 # -This comes from NOAA
 # -Resoultion is 25km*25km. Missing data is recorded by -9999
```

## Question 2:

Construct the necessary code to import this data set

```{r}
#there is 12 files for each month
#I need to combine them and read them in

endings = c("N_01_extent_v3.0.csv","N_02_extent_v3.0.csv", "N_03_extent_v3.0.csv", 
            "N_04_extent_v3.0.csv", "N_05_extent_v3.0.csv", "N_06_extent_v3.0.csv", 
            "N_07_extent_v3.0.csv", "N_08_extent_v3.0.csv", "N_09_extent_v3.0.csv", 
            "N_10_extent_v3.0.csv" , "N_11_extent_v3.0.csv", "N_12_extent_v3.0.csv")
urls = paste0("https://noaadata.apps.nsidc.org/NOAA/G02135/north/monthly/data/", endings)

```

## Question 3:

Plot the data and describe the trends you observe.

```{r}
arctic_ice = read_csv(urls) #reading in data

```

```{r}
arctic_ice = arctic_ice %>%
  filter(!if_any(everything(), ~ . == -9999)) %>% #gets rid of the missing data
  mutate(decimal_date = year + (mo - 1) / 12) #combine month and year data into a decimal date column
arctic_ice
```

```{r}
#this is kind of messy to look at. I think maybe I should average the year and plot that
ggplot(arctic_ice, aes(x = decimal_date)) +
  geom_line(aes(y = extent)) + 
  labs(title = "Sea Ice",
       x = "Year",
       y = "Northern Sea Ice Area (km)") +
  theme_minimal()
```

```{r}
#time to adjust the data again
arc_ice <- arctic_ice %>%
  group_by(year) %>% 
  summarise(avg_extent = mean(extent)) %>% #collect average of each year so to not include seasonal variation
  filter(year != 2025) #2025 is not finished, I noticed that its area seemed unusually high

```

```{r}
#plot data
ggplot(arc_ice, aes(x = year)) +
  geom_line(aes(y = avg_extent)) + 
  geom_smooth(aes(y = avg_extent)) + #i think a smoothing is necessary 
  labs(title = "Sea Ice",
       x = "Year",
       y = "Northern Sea Ice Area (km)") +
  theme_minimal()
```

```{r}
#yay looks great
#this is where I should start mapping this data
```

# Exercise V: Longer term trends in CO2 Records

The data we analyzed in the unit introduction included CO2 records dating back only as far as the measurements at the Manua Loa observatory. To put these values into geological perspective requires looking back much farther than humans have been monitoring atmosopheric CO2 levels. To do this, we need another approach.

[Ice core data](http://cdiac.ornl.gov/trends/co2/ice_core_co2.html):

Vostok Core, back to 400,000 yrs before present day

-   Description of data set: <http://cdiac.esd.ornl.gov/trends/co2/vostok.html>
-   Data source: <http://cdiac.ornl.gov/ftp/trends/co2/vostok.icecore.co2>

## Questions / Tasks:

-   Describe the data set: what are the columns and units? Where do the numbers come from?
-   What is the uncertainty in measurment? Resolution of the data? Interpretation of missing values?
-   Read in and prepare data for analysis.
-   Reverse the ordering to create a chronological record.
-   Plot data
-   Consider various smoothing windowed averages of the data.
-   Join this series to Mauna Loa data
-   Plot joined data
-   Describe your conclusions

```{r}
## Data set description
 # columns: Depth (m), Age of the ice (yr BP), Mean age of the air (yr BP), CO2 concentration (ppmv) and data comes from vostok ice core
# data kinda difficult to collect so go to website
# https://data.ess-dive.lbl.gov/view/doi:10.3334/CDIAC/ATG.009
# had to download the data and store it 'locally' on the server bc website didnt work
    #I fear lines may have been skipped because the data seems to have several tabs
    # Check for missing values (there are none that I can find)

df = read_table("~/ESPM288FINAL/vostok.icecore (3).co2" , skip = 20, col_names = c("depth", "age_of_ice","mean_age_air", "CO2"))
df
```

```{r}
sum(is.na(df)) #missing data check
```

```{r}
#plotting the data
ggplot(df, aes(x = age_of_ice * -1 + 2025)) + #reverse the data on the graph plus the year we are in
  geom_line(aes(y = CO2)) + 
  scale_x_continuous(labels = scales::comma) +
  labs(title = "CO2 in Atmosphere",
       x = "Year",
       y = "CO2 concentration (ppmv)") +
  theme_minimal()
```

```{r}
#time to combine this with the Muana Loa data

columns = c('year', 'month', 'decimal_date', 'average', 'smooth', 'std_days', 'uncertainty', 'empty')
df2 = read_table("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt", comment="#", col_names=columns)

# Perform the arithmetic operation to 'years ago'
df2 <- df2 %>%
  mutate(age = 2025.5 - decimal_date)

```

```{r}
#I am going to try to combine the data now (wish me luck)

df_monoloa <- df2 %>%
  select(age, average) %>%
  rename(age_value = age, co2_value = average)

df_cores <- df %>%
  select(age_of_ice, CO2) %>%
  rename(age_value = age_of_ice, co2_value = CO2)

# Now bind the rows together
CO2final <- bind_rows(df_monoloa, df_cores)

```

```{r}

ggplot(CO2final, aes(x = age_value * -1 )) + #reverse the data on the graph 
  geom_line(aes(y = co2_value)) + 
  scale_x_continuous(labels = scales::comma) +
  geom_smooth(aes(y = co2_value)) + #i think a smoothing is necessary 
  labs(title = "CO2 in Atmosphere",
       x = "Years Ago",
       y = "CO2 concentration (ppmv)") +
  theme_minimal()
```

OH NO it looks like there is CO2 cycles in the past except the last 100 years or so there is is ton of CO2 in the atmosphere.
